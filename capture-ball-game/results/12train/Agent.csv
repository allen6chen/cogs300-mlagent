Steps,Policy/Entropy,Policy/Extrinsic Value Estimate,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Epsilon,Policy/Beta,Is Training
50000,4.1526294,-1.3270994,724.3870967741935,3.973938185240953,3.973938185240953,214.72687,0.02501234,0.0002992266,0.1997422,0.0004987368,1.0
100000,4.1404076,-2.0334485,776.8064516129032,8.388454242098716,8.388454242098716,219.8455,0.02486663,0.00029783705,0.19927903,0.0004964672,1.0
150000,4.061494,-1.503192,698.4705882352941,180.01168955950175,180.01168955950175,876.95703,0.024197703,0.00029628977,0.19876327,0.00049393985,1.0
200000,3.8325193,3.3998213,830.78125,748.9149894579314,748.9149894579314,5045.1416,0.023881886,0.00029474427,0.19824807,0.0004914155,1.0
