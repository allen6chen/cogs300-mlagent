Steps,Policy/Entropy,Policy/Extrinsic Value Estimate,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Epsilon,Policy/Beta,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
50000,4.1544595,4.723321,3.8569427,0.024363104,0.00029922443,0.19974148,0.00049873325,1202.5294117647059,-14.798294442048405,-14.798294442048405,1.0
100000,4.14863,2.9978578,2.1387475,0.0275698,0.00029783018,0.19927672,0.00049645593,1202.3809523809523,-9.509309641041217,-9.509309641041217,1.0
150000,4.134414,2.2428257,1.2521124,0.02469989,0.00029628418,0.19876139,0.0004939308,1202.3809523809523,-6.356404709851458,-6.356404709851458,1.0
200000,4.103655,1.5233706,0.6762156,0.025286436,0.000294742,0.19824736,0.00049141195,1202.3809523809523,-2.77202367232669,-2.77202367232669,1.0
250000,4.0565157,1.0507303,0.37118357,0.02648069,0.00029319787,0.19773261,0.0004888898,1202.35,0.0448252234607935,0.0448252234607935,1.0
300000,3.9950614,0.7361953,0.5068254,0.025536548,0.00029165403,0.19721799,0.00048636817,1202.2857142857142,-0.46573769203608945,-0.46573769203608945,1.0
350000,3.9249623,0.4528317,0.8630266,0.023787452,0.00029026513,0.19675505,0.00048409973,1199.9285714285713,-0.5243088562662402,-0.5243088562662402,1.0
400000,3.8604748,0.2910396,3.5112267,0.023675293,0.0002888729,0.19629095,0.00048182564,1202.3181818181818,-5.407043667002157,-5.407043667002157,1.0
450000,3.81015,0.23929082,10.8608675,0.023736803,0.00028732148,0.19577384,0.00047929183,1197.25,-5.570323280151934,-5.570323280151934,1.0
500000,3.7760284,0.260094,23.65507,0.02523293,0.000285774,0.19525799,0.0004767642,1175.1,-11.25607072301209,-11.25607072301209,1.0
550000,3.6477802,0.24184515,36.32592,0.024115639,0.0002842253,0.19474176,0.00047423452,1170.4285714285713,-20.906661221668834,-20.906661221668834,1.0
