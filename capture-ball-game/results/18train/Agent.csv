Steps,Policy/Entropy,Policy/Extrinsic Value Estimate,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Epsilon,Policy/Beta,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
50000,4.207009,-4.9599595,63.316772,0.02597636,0.00029922443,0.19974148,0.00049873325,1190.5,-130.58634243556298,-130.58634243556298,1.0
100000,4.189453,-3.9153023,48.495323,0.025316903,0.00029783047,0.19927682,0.0004964564,1202.404761904762,-110.15892733012636,-110.15892733012636,1.0
150000,4.1702747,-3.3322651,37.38546,0.026139703,0.00029628156,0.1987605,0.00049392646,1202.3809523809523,-95.71433341147548,-95.71433341147548,1.0
200000,4.139892,-2.5036132,72.20909,0.025575418,0.00029473478,0.1982449,0.00049140013,1202.4,-108.46625329591333,-108.46625329591333,1.0
250000,4.091068,-2.1519148,59.665558,0.02350651,0.0002931869,0.19772899,0.000488872,1199.3333333333333,-117.16065965202593,-117.16065965202593,1.0
300000,4.044953,-2.051771,115.053566,0.02579698,0.00029164323,0.1972144,0.00048635062,1200.857142857143,-152.2562146743848,-152.2562146743848,1.0
350000,3.991989,-2.1836762,116.882965,0.027442105,0.00029025288,0.19675097,0.00048407965,1193.0227272727273,-142.44228076890465,-142.44228076890465,1.0
400000,3.9427066,-2.3087072,61.494728,0.026122833,0.00028886172,0.19628724,0.0004818074,1202.35,-122.56301280190903,-122.56301280190903,1.0
450000,3.8967457,-2.1659791,53.5223,0.025223989,0.00028732215,0.19577405,0.00047929276,1194.0238095238096,-121.2991864811629,-121.2991864811629,1.0
500000,3.8363569,-2.144687,86.542496,0.025990093,0.00028577948,0.19525984,0.00047677313,1202.35,-140.43984812963754,-140.43984812963754,1.0
550000,3.7808576,-2.2332118,97.82879,0.02625983,0.0002842375,0.19474582,0.0004742545,1202.2857142857142,-149.3180982510426,-149.3180982510426,1.0
